********************************************************** Quickstart Guide **********************************************************
**************************************************************************************************************************************

Workspace : evers_ws

In order to perform object training and detection, the following steps have to be done:

***Launch environment***:
1.	Source 
		cd ../evers_ws
		source devel/setup.bash

2.	Launch openni2
		
		roslaunch openni2_launch openni2.launch

3.	Launch Rqt-reconfigure and check in camera>driver “depth_registration”
		
		rosrun rqt_reconfigure rqt_reconfigure
			camera > driver > cocher « depth_registration »

4.	Launch ORK-tabletop
		
		rosrun object_recognition_core detection -c `rospack find    object_recognition_tabletop`/conf/detection.table.ros.ork

5.	Launch 
		
		roslaunch '/home/astrostudent/evers_ws/launch/evers_ws_recognition.launch'

6.	Launch Rviz and display : filtered_cloud(Pointcloud2) to check what clusters are being processed
         			         DetectedObjectsMarkers(Marker) to see what and where clusters have been detected
		
		rviz

***Training***:

8.	To train (fill the db with the scene_objects)
		
	 	2 ways to do training:
		1) Training with many objects on the table
			rosservice call /object_manager_srv train

			Note: The label and category of each object in db has to be written in info.json

		2) Training with one object on the table 			
			rosservice call /train_one_object_srv *label* *category* 

			Note 1: this service allows to give a label and a category during the training phase of an object in 					        order to do not have to write them by opening the info.json
			Note 2: if the service doesn't work it can come from the fact that the camera detects an object that 						you didn't expected

***Detection***:

9.	In order to perform all the detection steps and to see there results, the following node has to be run:
		(source devel/setup.bash)
		rosrun object_discrimination Objectdiscrimination 

10.	To launch a detection (Don’t forget to source)
		
	4 possibilities (example):
	1) rostopic pub discrim_status object_discrimination/DetectionInput "{'mode':'detect','label':['all'],'category':['all']}"
	2) rostopic pub discrim_status object_discrimination/DetectionInput "{'mode':'detect','label':['all'],'category':['cat1']}"
	3) rostopic pub discrim_status object_discrimination/DetectionInput "{'mode':'detect','label':['bean'],'category':['all']}"
	4) rostopic pub discrim_status object_discrimination/DetectionInput "{'mode':'detect','label':['bean'],'category':['cat1']}"


		
		




