******************************Fait******************************   

i)	Détection des plans : extraction de toutes les surfaces planes situées face à la caméra (framework déja existant : ORK) > puis extraction du plan le plus proche et horizontale (utilsation d'un second filtre)
        >la frame du plan le plus proche est retournée permettant de connaitre la position de la table par rapport au robot.
ii)	 Extraction des objets situés au dessus du plan sous forme de cluster (Pour l’instant objets situés a x cm au dessus du plan)
iii) Utilisation des clusters pour extraire l'image d'un l'objet (à partir de l'image rgb retournée par la caméra et des coordonnées des clusters)
iv)	Phase de training (cf quick start guide pour les noeuds ros à lancer):
    a.	remplissage de la bdd  (dossier db)
    b.	un dossier est créé pour chaque objet de la table 
    c.	dossier contient:
        i.	 image rgb de l'objet (cluster.png)
        ii.	 clusters sous forme brut (cluster.pcd et cluster.txt)
        iii.	 info.txt (contient: label, catégorie et autre information lié à l'objet)
v)	Phase de détection (cf quick start guide pour les noeuds ros à lancer)::
    1ère possibilité:
            a.	On indique via un topic le label d'un objet que l'on veut identifier ainsi qu'une catégorie (optionel)
                > rostopic pub discrim_status object_discrimination/DetectionInput "{'mode':'detect','label':['*label*']}"
            b.	Si le label correspond au label d’un objet stocké dans la bdd alors le processus de comparaison entre l’image issue de la bdd et            les images courantes des objets situés sur la tabletop est lancé (méthode de matching : surf …)
            c.	Une information de présence ou non de l’objet demandé sur la tabletop est ensuite retourné
            d.	Info retour ? sous quelle forme ?
     2ème possibilité:                
            a.	Demande au software ce qu’il y a sur la table (reviens à mettre 'all' dans label')
                > rostopic pub discrim_status object_discrimination/DetectionInput "{'mode':'detect','label':['all']}"
            b.	Extraction des clusters correspondants aux  objets sur la table
            c.	Comparaison des clusters avec les clusters des objets stockés en bdd afin de filtrer les objets non ressemblant avant de passer à la comparaison des images rgb
            d.	Si match entre cluster alors les étapes suivantes sont réalisées
            e.	Extraction de l’image rgb des objets situés sur la table
            f.	Comparaison des images extraites avec images de la base de donnée (méthode de matching : surf …)
            g.	Si concordance entre image alors l’objet est connu par le soft
            h.	Donc possibilité de donné le nom des objets situés sur la table
            
******************************A corriger/Améliorer******************************
i) amélioration méthode matching image rgb ?
ii) amélioration méthode de comparaison des clusters
iii) Remplacer texte en dur de info.txt en JSON 
+ mettre en place parsage JSON
iv)	Multi-threading pour optimisation processus de filtrage bdd
v) améliorer robustesse
vi) changer chemins absolus en chemins relatifs
vii) script python qui modifie nom dossier db à partir de info.txt
viii) Modification phase d'apprentissage : laisser la possibilité au user de nommer directement un objet détecté (pour eviter d'avoir a changer le label dans info.txt)

****************************** En cours ******************************
i) remplissage bdd
ii) réfléchir autre caractéristique de comparaison des clusters
iii) mettre en place new methodes de fitting

****************************** Nos modifications ******************************
i) Correction erreur detection avec rostopic pub ..."{'mode':'detect','label':['all']}" > gestion du cas ou aucune catégorie n'est spécifiée
        > classe modifiée : Objectdiscrimination
